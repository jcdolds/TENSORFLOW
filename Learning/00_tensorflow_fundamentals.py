# -*- coding: utf-8 -*-
"""00_tensorflow_fundamentals.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ChVi0FvHMaTlo5mgMgQC0ZHvaXjtOfd

**In this notebook, we're going to cover the most undamental concepts of tensors using TensorFlow**

More specifically,we're going to cover:


*   Introductions to tensors
*   Hetting informatio from tensore
*   Manipulating tensors
*   Tensors & NumPy

**Introduction to TensorFlow**
"""

#Import TensorFlow
import tensorflow as tf
print(tf.__version__)

# Create tensors with tf.constant()
scalar = tf.constant(7)
scalar

# Check the number of dimensions of a tensor (ndim stands for number of dimensions)
scalar.ndim

# Create a vector
vector = tf.constant([10,10])
vector

# Check the dimensions of our vector
vector.ndim

# Create a matrix (has more than 1 dimension)
matrix = tf.constant([[10,7],[7,10]])
matrix

matrix.ndim

from numpy import dtype
# Create another matrix
another_matrix = tf.constant([[10.,7.],
                              [3.,2.],
                              [8.,9.]],dtype=tf.float16) #specify the data type
another_matrix

# What's the number of dimensions of a matrix
another_matrix.ndim

#Let's create a tensor
tensor = tf.constant([ [[1,2,3,],[4,5,6]],
                       [[7,8,9],[10,11,12]],
                       [[13,14,15],[16,17,18]]  ])
tensor

tensor.ndim

""" ### Creating Tensors with Variable"""

# Create the same tensor with tf.Variable() as above
changeable_tensor = tf.Variable([10,7])
unchangeable_tensor = tf.constant([10,7])
changeable_tensor,unchangeable_tensor

# Let's try change one of the elements in our changeable tensor
changeable_tensor[0] = 7
changeable_tensor

# How about we try .assingn()
changeable_tensor[0].assign(7)
changeable_tensor

# Let's try change our unchangable tensor
unchangeable_tensor[0].assign(7)
unchangeable_tensor

""" ### Creating random tensors
 Random tensors 

"""

# Create random tensors
random_1 = tf.random.Generator.from_seed(7)
random_1 = random_1.normal(shape=(3,2))
random_2 = tf.random.Generator.from_seed(7)
random_2 = random_2.normal(shape=(3,2))

# Are they equal?
random_1,random_2,random_1 == random_2

"""### Suffle the order of elements in a tensor"""

# Shuffle a tensor (valueable for when you data so the inherent)
not_suffled = tf.constant([[10,7],[3,4],[2,5]])

# Suffle our non-shuffle_tesnor
tf.random.shuffle(not_suffled)

# Suffle our non-shuffle_tesnor
tf.random.set_seed(42)
tf.random.shuffle(not_suffled,seed=42)

tf.random.shuffle(not_suffled,seed=42)

"""It looks like if we want our shuffled tensor to be in the same order, we got to use the global level random seed:

### Other ways to make tenses
"""

tf.ones([10,7])

# Create a tensor of all zeroes
tf.zeros(shape=(3,4))

"""### Turn NumPy awways into tensors

"""

# You can also turn NumPy arrays into tensors
import numpy as np
numpy_A = np.arange(1,25,dtype=np.int32)
numpy_A

#x = tf.constant(some_matrix)
#y = tf.constant(vector)

A = tf.constant(numpy_A, shape=(3,8))
B = tf.constant(numpy_A)
A,B

"""### Getting information from TensorFlow"""

# Create a rank 4 tensor (4 dimensions)
rank_4_tensor = tf.zeros(shape=[2,3,4,5])
rank_4_tensor

rank_4_tensor[0]

rank_4_tensor.shape,rank_4_tensor.ndim,tf.size(rank_4_tensor)

# Get various attribute of our tensor
print("Datatype of every element: ",rank_4_tensor.dtype)
print("Number of dimensions (rank): ",rank_4_tensor.ndim)
print("Sahpe of tensor: ",rank_4_tensor.shape)
print("Elements along the 0 axis: ",rank_4_tensor.shape[0])
print("Elements along the last axis: ",rank_4_tensor.shape[-1])
print("Total number of elements in our tensor: ",tf.size(rank_4_tensor))
print("Total number of elements in our tensor: ",tf.size(rank_4_tensor).numpy)

"""### Indexing tensors

Tensors can be indexed just like Python lists.
"""

some_list = [1,2,3,4]
some_list[:2]

# Get the first 2 elements of each dimension
rank_4_tensor[:2,:2,:2,:2]

# Create a tensor(3,2) tensor
X = tf.constant([[1,2],[3,4],[5,6]])
Y = tf.constant([[7,8],[9,10],[11,12]])
X,Y

# let's change the shape of Y
tf.reshape(Y,shape=(2, 3))

X.shape,tf.reshape(Y, shape=(2,3)).shape

tf.matmul(X,tf.reshape(Y, shape=(2,3)))

tf.reshape(X,shape=(2,3)).shape, Y.shape

# Can do the same with transpose
X,tf.transpose(X),tf,tf.reshape(X,shape=(2,3))

# Try matrix multiplication with transpose rather than reshape
tf.matmul(tf.transpose(X),Y)

"""### the dot product
Matriz multiplication is also referred to as the dot product.
"""

X,Y

# Perform the dot product on x and y (requires x or y to be transposed)
tf.tensordot(tf.transpose(X),Y,axes = 1)

# Perform matrix multiplication between X and Y (transposed)
tf.matmul(X, tf.transpose(Y))

# PErform matrix multiplication between X and Y (reshaped)
tf.matmul(X, tf.reshape(Y,shape=(2,3)))

# Check the values of Y, reshape Y 
print("Normal Y:")
print(Y,"\n")

print("Y reshape to (2,3):")
print(tf.reshape(Y,shape=(2,3)),"\n")

print("transpose:")
print(tf.transpose(Y),"\n")

tf.matmul(X,tf.transpose(Y))

"""### Changing the datatype of a tensor"""

# Create a new tensor with default datatype (float32)
b = tf.constant([1.7,7.4])
b.dtype

c = tf.constant([17,74])
c.dtype

# Change from float32 to float16
b = tf.cast(b,dtype=tf.float16)
b,b.dtype

# Change from int32 to float32
e = tf.cast(c,dtype=tf.float32)
e

e_float16 = tf.cast(e,dtype=tf.float16)
e_float16

"""### Aggregating tensors

Aggregating tensor = condesing the from multiple values down to a smaller amount of values.
"""

# Get the absulte values
b = tf.constant([-7,-10])
b

# make all the elements in the matrix be positive.
tf.abs(b)

"""### Let's go throught the next aggregations."""

# Create a random tensor with values betwwen 0 and 100 of size 50
e = tf.constant(np.random.randint(0,100,size = 50))
e

tf.size(e), e.shape,e.ndim

#Min of the matriz
tf.reduce_min(e)

#Max of the matriz
tf.reduce_max(e)

#Mean of the matriz
tf.reduce_mean(e)

tf.reduce_sum(e)

# The variance , we can the type of data to work is very important.
import tensorflow_probability as tfp

tfp.stats.variance(e)

# Tensor desviation
# check the information and concepts because it helps you to know what type of data

tf.math.reduce_std(tf.cast(e,dtype=tf.float32))

"""### Find the promotional maximum and minimum"""

# Create a new tensor for finding positional minimum and maxium.
tf.random.set_seed(42)
f = tf.random.uniform(shape=[50])
f

# Fin the positional maximun
tf.argmax(f)

# index on our largest value position
f[tf.argmax(f)]

tf.reduce_max(f)

tf.reduce_max(f) == f[tf.argmax(f)]

# Find the position minium
tf.argmin(f)

# Find the minium using the positional minium index
f[tf.argmin(f)]

tf.reduce_min(f)

"""### Squeezing a tensor (removing all single dimensions)"""

# Create a tensor to get started
g = tf.constant(tf.random.uniform(shape=[50]), shape=(1,1,1,1,50))

g

g.shape

# Reduze singular lines
g_squeezed = tf.squeeze(g)
g_squeezed,g_squeezed.shape

"""### What is hot encoding"""

# Create a list of indices
some_list = [0,1,2,3] # red,gree,,blue, pruple

# One hot enconde our list of indice
tf.one_hot(some_list,depth=4)

# Specify custom values for one hot encoding
tf.one_hot(some_list,depth = 4, 
            on_value = "HGola",
            off_value="IShao")

"""### Squaring,log,square root"""

# Create a new tensor
h = tf.range(1,10)
h

# Square it
tf.square(h)

# the squaret root
tf.square(tf.cast(h,dtype=tf.float32))

# Fin the log
tf.math.log(tf.cast(h,dtype=tf.float32))

"""### Tensors and NumPy"""

# Create a tensor directly from a Numpy array
j = tf.constant(np.array([3.,7.,10.]))
j

# Convert our tensor back to a numpy array
np.array(j),type(np.array(j))

j.numpy(),type(j.numpy())

j = tf.constant([3.])
j.numpy()[0]

# The default types of each are slightly different
numpy_j = tf.constant(np.array([3.,7.,10.]))
tensor_j = tf.constant([3.,7.,10.])
numpy_j.dtype,tensor_j.dtype

"""### Finding access to GPU's"""

import tensorflow as tf
tf.config.list_physical_devices()

!nvidia-smi

"""**Note:** IF you have access to a CUDA-enable GPU, tensor will automatically

### 00. TensorFlow Fundamentals Exercises
"""

# Create a vector, scalar, matrix and tensor with values of your choosing using tf.constant()
import tensorflow as tf
mytensor = tf.constant([3.,7.,10.])
mytensor

# Find the shape, rank and size of the tensors you created in 1
mytensor.shape, tf.rank(mytensor),tf.size(mytensor)

#Create two tensors containing random values between 0 and 1 with shape [5, 300]

random_1 = tf.random.uniform(shape=[5,300], minval=0., maxval=1)
random_1

random_2 = tf.random.uniform(shape=[5,300], minval=0., maxval=1)
random_2

#a =  tf.constant(tf.random.uniform(shape=[0, 1)), shape=(5,300))

# Multiply the two tensors you created in 3 using matrix multiplication.
matrix_1 = tf.reshape(random_1,[500,3])
matrix_1

matrix_2 = tf.reshape(random_2,[500,3])
matrix_2

tf.math.multiply(matrix_1,matrix_2)

#Multiply the two tensors you created in 3 using dot product.
#tf.tensordot(matrix_1,matrix_2,axes = 1)
tf.matmul(matrix_1, tf.transpose(matrix_2))

#Create a tensor with random values between 0 and 1 with shape [224, 224, 3]
random_3 = tf.random.uniform(shape=[224, 224, 3], minval=0., maxval=1)
random_3

# Find the min and max values of the tensor you created in 6 along the first axis.

tf.reduce_min(random_3),tf.reduce_max(random_3)

# Created a tensor with random values of shape [1, 224, 224, 3] then squeeze it to change the shape to [224, 224, 3]
random_4 = tf.random.uniform(shape=[1, 224, 224, 3])
#random_4

random_4_squeezed = tf.squeeze(tf.reshape(random_4,[224, 224, 3]))
random_4_squeezed,random_4_squeezed.shape

# Create a tensor with shape [10] using your own choice of values, then find the index which has the maximum value.
a = tf.constant([1,2,3,4,5,6,7,8,9,10])
tf.reduce_max(a)

# One-hot encode the tensor you created in 9

tf.one_hot(a,depth=4)